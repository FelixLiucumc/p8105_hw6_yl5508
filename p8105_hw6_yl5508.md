p8105_hw6_yl5508
================
Yifei LIU
2023/11/27

It’s a proj for HW6 about LINEAR MODELS.  

``` r
library(tidyverse)
library(purrr)
library(modelr)
set.seed(1)
```

## Problem 1

``` r
vic_clean =
  read_csv("./data/homicide-data.csv", na = c("", "NA", "Unknown")) |>
  janitor::clean_names() |>
  mutate(city_state = str_c(city, ", ", state),
         victim_age = as.numeric(victim_age)) |>
  mutate(result = case_when(
    disposition == "Closed by arrest" ~ 1,
    disposition == "Closed without arrest" | disposition == "Open/No arrest" ~ 0
  )) |>
  filter(city_state != "Dallas, TX") |>
  filter(city_state != "Phoenix, AZ") |>
  filter(city_state != "Kansas City, MO") |>
  filter(city_state != "Tulsa, AL") |>
  filter(victim_race == "White" | victim_race == "Black") |> 
  select(city_state, result, victim_age, victim_sex, victim_race)
```

``` r
bal_glm = 
  filter(vic_clean, city_state == "Baltimore, MD") |> 
  glm(result ~ victim_age + victim_sex + victim_race, family = binomial(), data = _)

bal_glm |> 
  broom::tidy() |>
  knitr::kable(digits = 3)
```

| term             | estimate | std.error | statistic | p.value |
|:-----------------|---------:|----------:|----------:|--------:|
| (Intercept)      |    0.310 |     0.171 |     1.810 |   0.070 |
| victim_age       |   -0.007 |     0.003 |    -2.024 |   0.043 |
| victim_sexMale   |   -0.854 |     0.138 |    -6.184 |   0.000 |
| victim_raceWhite |    0.842 |     0.175 |     4.818 |   0.000 |

``` r
bal_glm |>
  broom::tidy() |>
  filter(term == "victim_sexMale") |>
  mutate(OR = exp(estimate),
         OR_CI_upper = exp(estimate + 1.96 * std.error),
         OR_CI_lower = exp(estimate - 1.96 * std.error)) |> 
  select(OR, OR_CI_lower, OR_CI_upper) |>
  knitr::kable(digits = 3)
```

|    OR | OR_CI_lower | OR_CI_upper |
|------:|------------:|------------:|
| 0.426 |       0.325 |       0.558 |

``` r
model_cities = 
  vic_clean |> 
  nest(data = -city_state) |> 
  mutate(models = map(data, \(df) glm(result ~ victim_age + victim_sex + victim_race, 
                             family = binomial(), data = df)),
    tidy_models = map(models, broom::tidy)) |> 
  select(-models, -data) |> 
  unnest(cols = tidy_models) |> 
  mutate(
    OR = exp(estimate), 
    OR_CI_upper = exp(estimate + 1.96 * std.error),
    OR_CI_lower = exp(estimate - 1.96 * std.error)) |> 
  filter(term == "victim_sexMale") |> 
  select(city_state, OR, OR_CI_lower, OR_CI_upper)

model_cities |>
  knitr::kable(digits = 3)
```

| city_state         |    OR | OR_CI_lower | OR_CI_upper |
|:-------------------|------:|------------:|------------:|
| Albuquerque, NM    | 1.767 |       0.831 |       3.761 |
| Atlanta, GA        | 1.000 |       0.684 |       1.463 |
| Baltimore, MD      | 0.426 |       0.325 |       0.558 |
| Baton Rouge, LA    | 0.381 |       0.209 |       0.695 |
| Birmingham, AL     | 0.870 |       0.574 |       1.318 |
| Boston, MA         | 0.667 |       0.354 |       1.260 |
| Buffalo, NY        | 0.521 |       0.290 |       0.935 |
| Charlotte, NC      | 0.884 |       0.557 |       1.403 |
| Chicago, IL        | 0.410 |       0.336 |       0.501 |
| Cincinnati, OH     | 0.400 |       0.236 |       0.677 |
| Columbus, OH       | 0.532 |       0.378 |       0.750 |
| Denver, CO         | 0.479 |       0.236 |       0.971 |
| Detroit, MI        | 0.582 |       0.462 |       0.734 |
| Durham, NC         | 0.812 |       0.392 |       1.683 |
| Fort Worth, TX     | 0.669 |       0.397 |       1.127 |
| Fresno, CA         | 1.335 |       0.580 |       3.071 |
| Houston, TX        | 0.711 |       0.558 |       0.907 |
| Indianapolis, IN   | 0.919 |       0.679 |       1.242 |
| Jacksonville, FL   | 0.720 |       0.537 |       0.966 |
| Las Vegas, NV      | 0.837 |       0.608 |       1.154 |
| Long Beach, CA     | 0.410 |       0.156 |       1.082 |
| Los Angeles, CA    | 0.662 |       0.458 |       0.956 |
| Louisville, KY     | 0.491 |       0.305 |       0.790 |
| Memphis, TN        | 0.723 |       0.529 |       0.988 |
| Miami, FL          | 0.515 |       0.304 |       0.872 |
| Milwaukee, wI      | 0.727 |       0.499 |       1.060 |
| Minneapolis, MN    | 0.947 |       0.478 |       1.875 |
| Nashville, TN      | 1.034 |       0.685 |       1.562 |
| New Orleans, LA    | 0.585 |       0.422 |       0.811 |
| New York, NY       | 0.262 |       0.138 |       0.499 |
| Oakland, CA        | 0.563 |       0.365 |       0.868 |
| Oklahoma City, OK  | 0.974 |       0.624 |       1.520 |
| Omaha, NE          | 0.382 |       0.203 |       0.721 |
| Philadelphia, PA   | 0.496 |       0.378 |       0.652 |
| Pittsburgh, PA     | 0.431 |       0.265 |       0.700 |
| Richmond, VA       | 1.006 |       0.498 |       2.033 |
| San Antonio, TX    | 0.705 |       0.398 |       1.249 |
| Sacramento, CA     | 0.669 |       0.335 |       1.337 |
| Savannah, GA       | 0.867 |       0.422 |       1.780 |
| San Bernardino, CA | 0.500 |       0.171 |       1.462 |
| San Diego, CA      | 0.413 |       0.200 |       0.855 |
| San Francisco, CA  | 0.608 |       0.317 |       1.165 |
| St. Louis, MO      | 0.703 |       0.530 |       0.932 |
| Stockton, CA       | 1.352 |       0.621 |       2.942 |
| Tampa, FL          | 0.808 |       0.348 |       1.876 |
| Tulsa, OK          | 0.976 |       0.614 |       1.552 |
| Washington, DC     | 0.691 |       0.469 |       1.018 |

``` r
model_cities |> 
  mutate(city_state = fct_reorder(city_state, OR)) |> 
  ggplot(aes(x = OR, y = city_state)) + 
  geom_point() + 
  geom_errorbar(aes(xmin = OR_CI_lower, xmax = OR_CI_upper)) + 
  labs(x = 'OR', y = 'city_state', title = 'Estimated ORs for cities') +
  theme_minimal()
```

![](p8105_hw6_yl5508_files/figure-gfm/unnamed-chunk-4-1.png)<!-- -->

Comment: Albuquerque shows a highest OR and New York shows the lowest.

## Problem 2

``` r
weather_df = 
  rnoaa::meteo_pull_monitors(
    c("USW00094728"),
    var = c("PRCP", "TMIN", "TMAX"), 
    date_min = "2022-01-01",
    date_max = "2022-12-31") |>
  mutate(
    name = recode(id, USW00094728 = "CentralPark_NY"),
    tmin = tmin / 10,
    tmax = tmax / 10) |>
  select(name, id, everything())
```

``` r
temp_boot =
  weather_df |>
  modelr::bootstrap(n = 5000) |>
  mutate(
    models = map(strap, \(df) lm(tmax ~ tmin + prcp, data = df)),
    results = map(models, broom::tidy),
    r_squared = map(models, broom::glance)
  ) |>
  unnest(results) |>
  select(id = .id, term, estimate, r_squared) |>
  pivot_wider(names_from = term, values_from = estimate) |>
  unnest(r_squared) |>
  select(id, r_squared = r.squared, beta_1 = tmin, beta_2 = prcp) |>
  mutate(log_beta = log(beta_1 * beta_2))

#show generated results
temp_boot |>
  head(10) |>
  knitr::kable(digits = 3)
```

| id   | r_squared | beta_1 | beta_2 | log_beta |
|:-----|----------:|-------:|-------:|---------:|
| 0001 |     0.898 |  0.972 |  0.004 |   -5.436 |
| 0002 |     0.928 |  1.021 | -0.007 |      NaN |
| 0003 |     0.925 |  1.033 | -0.008 |      NaN |
| 0004 |     0.931 |  1.009 | -0.010 |      NaN |
| 0005 |     0.915 |  1.008 | -0.004 |      NaN |
| 0006 |     0.918 |  1.008 |  0.001 |   -7.180 |
| 0007 |     0.922 |  1.023 | -0.003 |      NaN |
| 0008 |     0.910 |  1.037 |  0.001 |   -6.654 |
| 0009 |     0.910 |  1.005 |  0.002 |   -6.212 |
| 0010 |     0.939 |  1.023 | -0.006 |      NaN |

``` r
#report # of NA in log calculation
tibble(
  count_na = sum(is.na(temp_boot$log_beta)),
  count_total = nrow(temp_boot),
  percent_na = sum(is.na(temp_boot$log_beta)) / nrow(temp_boot)
  ) |>
  knitr::kable()
```

| count_na | count_total | percent_na |
|---------:|------------:|-----------:|
|     3361 |        5000 |     0.6722 |

Comment: There are a total of 3361 NA in all log calculations,
accounting for 67.2% of the overall results.

``` r
#trim NA off
temp_boot_tidy =
  temp_boot |>
  drop_na()
```

``` r
temp_boot |>
  ggplot(aes(x = r_squared)) +
  geom_density() +
  labs(x = "R^2 Estimates", y = "Density", title = "Distribution of R Squared Estimates") +
  theme_minimal()
```

![](p8105_hw6_yl5508_files/figure-gfm/unnamed-chunk-9-1.png)<!-- -->

Comment: The distribution of r squared is approximately normal,
left-skewed if being rigorous. The mean value of r squared would be
about 0.92, and most of the sample points lie in a range larger than 0.9
indicating that there is a strong linear relation shown by the model.

``` r
temp_boot_tidy |>
  ggplot(aes(x = log_beta)) +
  geom_density() +
  labs(x = "log(β1*β2) Estimates", y = "Density", title = "Distribution of log(β1*β2) Estimates") +
  theme_minimal()
```

![](p8105_hw6_yl5508_files/figure-gfm/unnamed-chunk-10-1.png)<!-- -->

Comment: The sample points are relatively concentrated, predominantly
distributed within the range of -6 to -5. There are a considerable
number of outliers on the left side, indicating a left-skewed
distribution.

``` r
temp_boot |> 
  summarize(
    ci_lower_r2 = quantile(r_squared, 0.025), 
    ci_upper_r2 = quantile(r_squared, 0.975)) |>
  knitr::kable(digits = 3)
```

| ci_lower_r2 | ci_upper_r2 |
|------------:|------------:|
|       0.889 |       0.941 |

``` r
temp_boot_tidy |> 
  summarize(
    ci_lower_log = quantile(log_beta, 0.025, na.rm = TRUE), 
    ci_upper_log = quantile(log_beta, 0.975, na.rm = TRUE)) |>
  knitr::kable(digits = 3)
```

| ci_lower_log | ci_upper_log |
|-------------:|-------------:|
|       -8.982 |       -4.602 |

Comment: The 95% confidence interval for r^2 is (0.9, 0.9). The 95%
confidence interval for r^2 is (-9, -4.6).

## Problem 3

``` r
bw_clean =
  read_csv("./data/birthweight.csv") |>
  janitor::clean_names() |>
  mutate(
    babysex = case_when(
      babysex == 1 ~ "male",
      babysex == 2~ "female"),
    frace = case_when(
      frace == 1 ~ "White",
      frace == 2 ~ "Black",
      frace == 3 ~ "Asian",
      frace == 4 ~ "Puerto Rican",
      frace == 8 ~ "Other",
      frace == 9 ~ "Unknown"),
    malform = case_when(
      malform == 0 ~ 'absent',
      malform == 1 ~ 'present'),
    mrace = case_when(
      mrace == 1 ~ "White",
      mrace == 2 ~ "Black",
      mrace == 3 ~ "Asian",
      mrace == 4 ~ "Puerto Rican",
      mrace == 8 ~ "Other")
  ) |>
  select(-pnumlbw, -pnumsga)

sum(is.na(bw_clean))
```

    ## [1] 0

Comment: No NA in this dataset. No need for trimming.

``` r
model_bw = lm(bwt ~ ., data = bw_clean) |>
  step(direction = "both", trace = FALSE)
summary(model_bw) |>
  broom::tidy() |>
  knitr::kable(digits = 3)
```

| term              |  estimate | std.error | statistic | p.value |
|:------------------|----------:|----------:|----------:|--------:|
| (Intercept)       | -6145.151 |   141.950 |   -43.291 |   0.000 |
| babysexmale       |   -28.558 |     8.455 |    -3.378 |   0.001 |
| bhead             |   130.777 |     3.447 |    37.944 |   0.000 |
| blength           |    74.947 |     2.019 |    37.120 |   0.000 |
| delwt             |     4.107 |     0.392 |    10.475 |   0.000 |
| fincome           |     0.318 |     0.175 |     1.820 |   0.069 |
| gaweeks           |    11.592 |     1.462 |     7.929 |   0.000 |
| mheight           |     6.594 |     1.785 |     3.694 |   0.000 |
| mraceBlack        |   -63.906 |    42.366 |    -1.508 |   0.132 |
| mracePuerto Rican |   -25.791 |    45.350 |    -0.569 |   0.570 |
| mraceWhite        |    74.887 |    42.315 |     1.770 |   0.077 |
| parity            |    96.305 |    40.336 |     2.388 |   0.017 |
| ppwt              |    -2.676 |     0.427 |    -6.261 |   0.000 |
| smoken            |    -4.843 |     0.586 |    -8.271 |   0.000 |

Comment: I attempted a data-driven modeling approach by initially
introducing all variables into a linear regression model. Then,
employing a stepwise “both” selection method, the function evaluated the
importance of variables within the model (p_value). Ultimately, the
model results included variables babysex, bhead, blength, delwt,
fincome, gaweeks, mheight, mrace, parity, ppwt, smoken.

``` r
res = bw_clean |>
  modelr::add_predictions(model_bw) |>
  modelr::add_residuals(model_bw)

res |>
  ggplot(aes(x = pred, y = resid)) +
  geom_point(alpha = .5) +
  stat_smooth(method = "lm") +
  labs(x = "Predictions", y = "Residuals", title = "Residuals against Predictions") +
  theme_minimal()
```

![](p8105_hw6_yl5508_files/figure-gfm/unnamed-chunk-14-1.png)<!-- -->

``` r
model_com_1 = lm(bwt ~ blength + gaweeks, data = bw_clean)
summary(model_com_1)
```

    ## 
    ## Call:
    ## lm(formula = bwt ~ blength + gaweeks, data = bw_clean)
    ## 
    ## Residuals:
    ##     Min      1Q  Median      3Q     Max 
    ## -1709.6  -215.4   -11.4   208.2  4188.8 
    ## 
    ## Coefficients:
    ##              Estimate Std. Error t value Pr(>|t|)    
    ## (Intercept) -4347.667     97.958  -44.38   <2e-16 ***
    ## blength       128.556      1.990   64.60   <2e-16 ***
    ## gaweeks        27.047      1.718   15.74   <2e-16 ***
    ## ---
    ## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
    ## 
    ## Residual standard error: 333.2 on 4339 degrees of freedom
    ## Multiple R-squared:  0.5769, Adjusted R-squared:  0.5767 
    ## F-statistic:  2958 on 2 and 4339 DF,  p-value: < 2.2e-16

``` r
model_com_2 = lm(bwt ~ bhead * blength * babysex, data = bw_clean)
summary(model_com_2)
```

    ## 
    ## Call:
    ## lm(formula = bwt ~ bhead * blength * babysex, data = bw_clean)
    ## 
    ## Residuals:
    ##      Min       1Q   Median       3Q      Max 
    ## -1132.99  -190.42   -10.33   178.63  2617.96 
    ## 
    ## Coefficients:
    ##                             Estimate Std. Error t value Pr(>|t|)    
    ## (Intercept)                -801.9487  1102.3077  -0.728 0.466948    
    ## bhead                       -16.5975    34.0916  -0.487 0.626388    
    ## blength                     -21.6460    23.3720  -0.926 0.354421    
    ## babysexmale               -6374.8684  1677.7669  -3.800 0.000147 ***
    ## bhead:blength                 3.3244     0.7126   4.666 3.17e-06 ***
    ## bhead:babysexmale           198.3932    51.0917   3.883 0.000105 ***
    ## blength:babysexmale         123.7729    35.1185   3.524 0.000429 ***
    ## bhead:blength:babysexmale    -3.8781     1.0566  -3.670 0.000245 ***
    ## ---
    ## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
    ## 
    ## Residual standard error: 287.7 on 4334 degrees of freedom
    ## Multiple R-squared:  0.6849, Adjusted R-squared:  0.6844 
    ## F-statistic:  1346 on 7 and 4334 DF,  p-value: < 2.2e-16

``` r
cv_bw =
  modelr::crossv_mc(bw_clean, 100)

cv_bw_rmse =
  cv_bw |>
  mutate(
    model_cv_full = map(cv_bw$train, 
                         \(df) lm(bwt ~ ., data = (df)) |>
                           step(direction = "both", trace = FALSE)),
    model_sample1 = map(cv_bw$train, 
                         \(df) lm(bwt ~ blength + gaweeks, data = (df))),
    model_sample2 = map(cv_bw$train, 
                         \(df) lm(bwt ~ bhead * blength * babysex, data = (df)))
  ) |>
  mutate(
    errs_cv_full = purrr::map2_dbl(model_cv_full, cv_bw$test, rmse),
    errs_sample1 = purrr::map2_dbl(model_sample1, cv_bw$test, rmse),
    errs_sample2 = purrr::map2_dbl(model_sample2, cv_bw$test, rmse)
  )

cv_bw_rmse |>
  select(model_gen = errs_cv_full,
         model_sample1 = errs_sample1,
         model_sample_2 = errs_sample2) |>
  pivot_longer(everything(), 
               names_to = "models",
               values_to = "rmse") |>
  mutate(model = factor(models, levels = c("model_gen", "model_sample1", "model_sample_2"))) |>
  ggplot(aes(x = model, y = rmse)) +
  geom_violin() +
  labs(x = "Models", y = "rmse", title = "Cross-Validated Prediction Error") +
  theme_minimal()
```

![](p8105_hw6_yl5508_files/figure-gfm/unnamed-chunk-16-1.png)<!-- -->

Comment: The model generated driven by data shows the best RMSE result.
The models constructed based on empirically selected variables show
poorer fit compared to the data-driven one. Specifically, the model
considering only `blength and`gaweeks\` exhibited the worst performance,
having the highest RMSE.
